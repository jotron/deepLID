          \section{Modelle}
Im folgenden Teil werden die entwickelten Deep Learning Modelle vorgestellt. Für jedes Modell ist der grundlegende Ablauf derselbe (siehe Abbildung \ref{img:workflow}). Die Aufnahme wird vorab auf die Länge 5s zugeschnitten. Anschliessend wird ein Spektrogramm generiert. Die Werte des Spektrogramms werden in die Dezibell Skala umgerechnet und dann normiert. Die Grösse des Spektrogramms unterscheidet sich zwischen den Modellen. Schliesslich berechnet ein Neuronales Netzwerk aus dem Spektogramm eine Vorhersage für die drei Sprachen. 
\\
Insgesamt werden drei grundsätzlich verschiedene Neuronalen Netzwerk Architekturen vorgestellt. Die ersten zwei Modelle sind Convolutional Neural Networks während das dritte Modell eine Kombination zwischen CNN und Recurrent Neural Network ist. Jedes Modell endet mit einer Ausgabeschicht der Grösse drei. Jeder der der drei Werte steht für die Wahrscheinlichkeit einer Sprache. Um zu garantieren, dass die Summe der Werte 1 gibt wird die Aktivierungsfunktion \textit{softmax} verwendet:
$$ \text{softmax}(\boldsymbol x)_i = \frac{\text{exp}(x_i)}{\sum_{j=0}^{n} \text{exp}(x_j)}$$
Beispiel: 
$$ \text{softmax}(\begin{bmatrix} 0.5 & 0.8 & 0.3\end{bmatrix}) = \begin{bmatrix} 0.32 & 0.43 & 0.26\end{bmatrix} = \begin{bmatrix} p_{FR} & p_{EN} & p_{DE}\end{bmatrix}$$
Die Funktion eignet sich generell für Klassifizierung, denn sie bildet die Werte auf eine Wahrscheinlichkeitsverteilung über die berechneten Ausgabeklassen ab \parencite[][S. 180-184]{goodfellow}. Für alle anderen Schichten wird immer die Aktivierungsfunktion \textit{ReLU} verwendet.
\\
Damit die Ziele des Netzwerks die gleichen Anzahl Dimensionen wie die Ausgaben haben, werden sie \textit{One-hot}\parencite{chollet} kodiert. Das bedeutet, dass die richtige Sprache die Wahrscheinlichkeit 1.0 besitzt und alle anderen 0. Das Ziel für eine französische Aufnahme ist also $\begin{bmatrix} 1.0 & 0.0 & 0.0\end{bmatrix}$, für eine englische Aufnahme $\begin{bmatrix} 0.0 & 1.0 & 0.0\end{bmatrix}$, etc.. Obwohl die Ziele die gleiche Form wie die Ausgaben haben lässt sich der Verlustwert nicht so leicht berechnen wie beim Anfangsbeispiel. Die Standard Verlustfunktion in diesem Fall ist \textit{Categorical Crossentropy}\parencite{chollet}. Für das Ziel $p$ und die Voraussage $\hat{p}$ ist die Funktion folgendermassen definiert:

$$\text{H}(\boldsymbol{p}, \hat{\boldsymbol{p}}) = \sum\limits_{i} p_i \cdot \text{log}(\hat{p_i})$$
\\
Das diese Verlustfunktion sinnvoll ist lässt sich intuitiv verstehen: Das Ziel des Netzes soll es sein, die Wahrscheinlichkeit der richtigen Sprache zu maximieren. So soll zum Beispiel bei $\boldsymbol{P}=\begin{bmatrix} 0 & 1.0 & 0\end{bmatrix}$ und $\boldsymbol{\hat{P}}=\begin{bmatrix} P_o & P_1 & P_2\end{bmatrix}$,  $ P_1$ maximiert werden. Die Wahrscheinlichkeit der richtigen Sprache lässt sich einfach berechnen:
$$\text{L}(\boldsymbol{p}, \hat{\boldsymbol{p}}) = \sum\limits_{i} p_i \cdot \hat{p_i}$$
Im Beispiel oben fallen $P_0$ und $P_2$ weg und $1\cdot P_1$ bleibt übrig, was genau der Wahrscheinlichkeit der richtigen Sprache entspricht. Ab hier lässt sich nachvollziehen, das genau wie wir $L$ maximieren wollen, $-L$ (wie der Verlustwert) minimiert werden soll. Da $\text{log}$ eine monotonische Funktion ist entspricht $\text{min}(p)$ auch $\text{min(log(}p))$. Das Resultat ist genau die Categorical Crossentropy.
$$\text{max}[\text{L}(\boldsymbol{p}, \hat{\boldsymbol{p}})] =\text{min}[-\text{L}(\boldsymbol{p}, \hat{\boldsymbol{p}})]$$
$$\text{min}[-\text{L}(\boldsymbol{p}, \hat{\boldsymbol{p}})] =\text{min}[-\text{L}(\boldsymbol{p}, \text{log}(\boldsymbol{\hat{p}}))] = \text{H}(\boldsymbol{p}, \hat{\boldsymbol{p}})$$
\\
Die Parameter der Modelle, wie zum Beispiel die Grösse des Spektrogramms wurden empirisch bestimmt. Insgesamt wurden fast 200 Experimente durchgeführt. Allerdings konnte längst nicht jede mögliche Kombination von Parametern probiert werden, da jeder Durchlauf zeitaufwändig und nicht parallelisierbar ist.
\begin{figure}[hbt]
	\centering
		\includegraphics[width=0.8\textwidth]{assets/modelflow.png}
	\caption{Grundlegender Aufbau aller Modelle}
	\label{img:workflow}
\end{figure}


\subsection{CNN}
Das CNN Netzwerk akzeptiert Spektrogramme der Grösse 28x313, wobei 28 verschiedene Mel-Frequenzeimer berechnet werden an 313 Zeitpunkten. Das Netz besteht aus drei Convolution-MaxPooling Blocks und zwei Dense Schichten (Abbildung \ref{img:cnn}). Die Convolution-Grösse ist immer 3x3 und MaxPooling geschieht im Bereich 2x2. Die Anzahl Convolution's (Kanäle) nimmt von 64 auf 128 zu. 
\\
Die \textit{Fully Connected} Schicht besteht aus 512 Knoten mit 30\% \textit{Dropout}. Bei Dropout wird ein zufälliger gewählter Anteil der Eingabe der Schicht mit 0 ersetzt. Das Netz lernt dann, ohne diese Verbindungen auszukommen und somit mehrere Verbindungen einzelnen starken Verbindungen vorzuziehen. Die Eigenschaft hat einen positiven Einfluss auf die Robustheit des Netzes gegenüber neuen Daten \parencite[][Kap. 4.4.3]{chollet}.
\\
Die Architektur entspricht massgeblich der vorgestellten Architektur in \parencite{iLID} plus Dropout.
 \begin{figure}[hbt]
	\centering
		\includegraphics[width=0.8\textwidth]{assets/cnn.png}
	\caption{CNN Architektur}
	\label{img:cnn}
\end{figure}

\subsection{MobileNet-CNN}
Andere Arbeiten hatten gezeigt, dass grosse CNN Architekturen die auf dem \textit{ImageNet}\parencite{imagenet} Datenset (Riesiges Bilddatenset mit tausenden Bidklassen) stark sind, ebenfalls für Audioklassifizierung geignet sind \parencite{cnn_large}. Um Leistung zu sparen wurden Experimente mit \textit{MobileNet} durchgeführt.
MobileNet ist eine bekannte CNN Architektur entwickelt von \textit{Google} \parencite[][(V2)]{mobilenet}. Das Modell ist speziell entwickelt für Mobilgeräte, die in der Regel schwächere Hardware als Desktop-Computer besitzen. Das Ziel war ein effizientes Netzwerk für Bilderkennung im grossen Umfang, wie z.B ImageNet. Da das Modell in dieser Arbeit nur zwischen drei Klassen unterscheiden muss, wird die Anzahl Knoten im Netzwerk so weit wie möglich verkleinert, bzw. der Parameter $\alpha$ im Paper wird auf 0.25 gesetzt. 
\\
Das Netzwerk besitzt insgesamt 21 Schichten. Das Netzt funktioniert am bessten mit Eingaben der Grösse 224x224, der Bildgrösse in ImageNet. Die Spektrogramme werden darum auf dieses Format skaliert.
 \begin{figure}[hbt]
	\centering
		\includegraphics[width=0.8\textwidth]{assets/mobilenet.png}
	\caption{MobileNet Architektur}
	\label{img:mobilenet}
\end{figure}

\subsection{CRNN}
Convolutional Recurrent Neural Networks, eine Mischung aus CNN und RNN, wurden bereits erfolgreich auf Sprachidentifikation angewendet \parencite{crnn}\parencite{yerevann}. RNN's für Tonaufnahmen zu verwenden ist sinnvoll, denn Audiodaten sind naturgemäss zeitliche Folgen, also ideal für RNN's. RNN's haben aber den Nachteil, dass sie langsam lernen. Darum soll der CNN Teil im Vorfeld aus dem Spektrogramm eine kompaktere Repräsentation berechnet, z.b eine Abfolge von Phonemen. Da die Lernzeit proportional zur Eingabegrösse ist, lernt der RNN teil mit dieser Eingabe schneller. Es gibt keine Möglichkeit zu verifizieren, ob das CNN wirklich Phoneme berechnet aber die Resultate zeigen, dass das CRNN besser abschneidet als das CNN.
\\
Der CNN Teil besteht aus fünf Blocks von Convolution, MaxPooling und \textit{Batch Normalization}\label{Batch Normalization} (Siehe Abbildung \ref{img:crnn}). Die Idee von \textit{Batch Normalization} ist, dass die Ausgabe der vorherigen Schicht so normalisiert wird, dass sie den Durchschnitt 0 und die Varianz 1 besitzt. \textit{Batch Normalization} bringt den vor allem den Vorteil, dass das Modell schneller konvergiert, also schneller bessere Leistungen erbringt. \parencite{batch}
\\
Die Anzahl Convolutions steigert sich schrittweise von 16 auf 64. Das Convolution-Fenster hat immer die Grösse 4x4 und MaxPooling das Fenster 2x2. Bei den Convolutions wird 0.01 \textit{L2-Regularisation} verwendet:
$$ Verlust = Verlust + \sum_{i} w_{i}^{2}$$
Das bedeutet, dass dem Verlustwert zusätzlich das Quadrat der Gewichte addiert wird \parencite[Kap.~7.1.1]{goodfellow}. Übermässig hohe Gewichte werden überproportial gewertet. Die Regularisation hat das gleiche Ziel wie Dropout, das Netz robuster zu gestalten.
\\

 \begin{figure}[hbt]
	\centering
		\includegraphics[width=0.8\textwidth]{assets/crnn.png}
	\caption{CRNN Architektur}
	\label{img:crnn}
\end{figure}

\section{Umsetzung und Resultate}

\subsection{Implementierung}

 \begin{figure}[hbt]
	\centering
		\includegraphics[width=1.0\textwidth]{assets/vorgang_small.png}
	\caption{Überblick über die Arbeitsschritte}
	\label{img:vorgehen}
\end{figure}


\subsection{Auswertung an Voxforge und YouTube}

\begin{table}[h]
	\centering
	\begin{tabular}{lllll}
		\hline
		Netz & Architektur     & Genauigkeit & Verlustwert & \\ \hline
		CNN  & 3 Conv          & 95\%     & 0.13  \\
		CRNN & 4 Conv + LSTM   & 97\%     & 0.15  \\
		MobileNet  & 28 Conv + Dense & 92\%     & 0.27  \\ \hline
	\end{tabular} \\
	\caption{Beste Voxforge Genauigkeit}
	\label{table:test_vox}
	\vspace{0.3cm}
	\begin{tabular}{lllll}
		\hline
		Netz & Architektur     & Genauigkeit & Verlustwert & \\ \hline
		CNN  & 3 Conv          & 95.1\%     & 0.15  \\
		CRNN & 4 Conv + LSTM   & 95\%     & 0.21  \\
		MobileNet  & 28 Conv + Dense & 87\%     & 0.48  \\ \hline
	\end{tabular}
	\caption{Beste YouTube Genauigkeit}
	\label{table:test_you}
\end{table}

\begin{table}[h]
	\centering
	\begin{tabular}{lll}
		\hline
		Netz & Trainingsdauer \\ \hline
		CNN  & 21 min \\
		CRNN & 68 min \\
		MobileNet  & 210 min\\ \hline
	\end{tabular}
	\caption{Trainingsdauer}
	\label{table:test}
\end{table}

 \begin{figure}[hbt]
	\centering
		\includegraphics[width=0.5\textwidth]{assets/matrix_vox.png}
	\caption{Wahrheitsmatrix Voxforge und Youtube (Total 10'000 Aufnahmen)}
	\label{img:matrix_vox}
\end{figure}

\subsection{Auswertung an Librivox}

\begin{table}[h]
	\centering
	\begin{tabular}{lllll}
		\hline
		Netz & Architektur     & Genauigkeit & Verlustwert \\ \hline
		CNN  & 3 Conv          & 88\%     & 0.34  \\
		CRNN & 4 Conv + LSTM   & 94\%     & 0.24  \\
		MobileNet  & 28 Conv + Dense & 94\%     & 0.19  \\ \hline
	\end{tabular}
	\caption{Beste Librivox Genauigkeit}
	\label{table:test_lib}
\end{table}

 \begin{figure}[hbt]
	\centering
		\includegraphics[width=0.5\textwidth]{assets/matrix_lib.png}
	\caption{Wahrheitsmatrix Librivox (Total 6120 Aufnahmen)}
	\label{img:matrix_lib}
\end{figure}
