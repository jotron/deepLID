{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Help\n",
    "This document explains all lines of code that are used in the individual model notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importieren von Bibliotheken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment can be used to log the training process on an external server\n",
    "from comet_ml import Experiment\n",
    "\n",
    "# Libary for Deep Learning\n",
    "import keras\n",
    "\n",
    "# Keras.layers contains all different types of layers \n",
    "from keras import layers\n",
    "\n",
    "# Keras.models.Model transforms a stack of layers in an actual Model\n",
    "from keras import models\n",
    "\n",
    "# Contains different regularization methods to apply to layers\n",
    "from keras import regularizers\n",
    "\n",
    "# Numpy is used for arrays and numerical computation\n",
    "import numpy as np\n",
    "\n",
    "# Matplotlib can create Diagrams and other Figures\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Keras Layer that applies the FFT to the raw input audio\n",
    "from kapre.time_frequency import Melspectrogram\n",
    "\n",
    "# Keras Layer that normalizes inputs\n",
    "from kapre.utils import Normalization2D\n",
    "\n",
    "# In order to import the self-written code in an other directory,\n",
    "# the path is added\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "# Import the self-written DataFeed class to load Data\n",
    "from utils import DataFeed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets the numpy random seed\n",
    "# this way the network weights will always be initialized the same way -> better comparable\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the common parent folder of voxforge, youtube and librivox data\n",
    "data_path= '../preprocessing/preprocessed_data'\n",
    "\n",
    "# Load 50000 samples from the 'train/voxforge' and 'train/youtube' folder\n",
    "#     If premade is true: load the predefined selection of 50'000 samples (originally there are 100000)\n",
    "#     train_data is array of 50'000 samples, train_labels is array of 50'000 solutions\n",
    "#     If shuffle=True: shuffle order of samples\n",
    "train_data, train_labels = DataFeed.Dataset.create(data_path, ['train/voxforge', 'train/youtube'], num=50000, use_premade=True)\n",
    "\n",
    "# Same as above but load validation data\n",
    "#     num=-1 indicates to load all available data\n",
    "val_data, val_labels = DataFeed.Dataset.create(data_path, ['val/youtube', 'val/voxforge'], num=-1, shuffle=True)\n",
    "\n",
    "# Instead of the procedure above, that load the entire data into RAM, use a generator\n",
    "#     Batch_size indicates how many samples will be processed at once\n",
    "#     The data will slowly arrive in Batches while Training\n",
    "training_generator = DataFeed.DataGenerator(data_path, ['train/voxforge', 'train/youtube'], num=-1, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks are executex at the end of each epoch (epoch means having processed all samples once)\n",
    "callbacks = [\n",
    "    # This callbacks looks at the val_acc and stops the training\n",
    "    # if the validation accuracy hasn't improved five times in a row\n",
    "    keras.callbacks.EarlyStopping(monitor='val_acc', patience=3),\n",
    "    \n",
    "    # This callback looks at the validation loss, if it is the best so far, it saves the model locally (as .h5)\n",
    "    keras.callbacks.ModelCheckpoint('berlin_net.h5', monitor='val_loss', save_best_only=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "melspectrogram_1 (Melspectro (None, 28, 313, 1)        270364    \n",
      "_________________________________________________________________\n",
      "normalization2d_1 (Normaliza (None, 28, 313, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 26, 311, 64)       640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 155, 64)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 13, 155, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 128960)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              132056064 \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 3075      \n",
      "=================================================================\n",
      "Total params: 132,330,143\n",
      "Trainable params: 132,059,779\n",
      "Non-trainable params: 270,364\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Creates the instance of a sequential Model\n",
    "# 'Sequential' means that all layers are simply chained after another\n",
    "model = models.Sequential()\n",
    "\n",
    "# Model.add(layer) adds the layer at the end of the model\n",
    "# Mespectrogram is special layer that applies the FFT to the input data\n",
    "#     input_shape: (num_channels, sample) sample = 5s * sr = 5* 16k = 80000, audio is always Mono\n",
    "#     n_dft: The number of DFT points, presumably power of 2\n",
    "#     fmin: minimal frequency\n",
    "#     fmax: maximal frequency\n",
    "#     sr: sample rate\n",
    "#     n_mels: number of frequency buckets = height of image\n",
    "#     trainable_x: allow the paramters to train\n",
    "#     return_decibel_melgram: convert to decibel\n",
    "model.add(Melspectrogram(n_dft=512, input_shape=(1, 5 * 16000,),\n",
    "                         padding='same', sr=16000, n_mels=28,\n",
    "                         fmin=0.0, fmax=10000, power_melgram=1.0,\n",
    "                         return_decibel_melgram=True, trainable_fb=False,\n",
    "                         trainable_kernel=False))\n",
    "\n",
    "# Normalizes entire data sample\n",
    "model.add(Normalization2D(str_axis='data_sample'))\n",
    "\n",
    "# A 2D Convolutional Layer\n",
    "#     with 64 nodes\n",
    "#     each node looks at 3x3 nodes from the previous layer\n",
    "#     activation_function is ReLU\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# A Maxpooling 2D Layer over the area 2x2\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Use 30% Dropout for next layer\n",
    "model.add(layers.Dropout(0.3))\n",
    "\n",
    "# If the output of the last layer is multi-dimensional, flatten it\n",
    "# e.g [[1],[1]] -> [1, 1]\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Fully Connected Layer with 1024 Nodes\n",
    "model.add(layers.Dense(1024, activation='relu'))\n",
    "\n",
    "# Fully Connected Layer with 3 nodes and activation function = Softmax\n",
    "model.add(layers.Dense(3, activation='softmax'))\n",
    "\n",
    "# Prints a summary of the network\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The summary shows the number of paramters per layer and the output shape of each layer.\n",
    "\n",
    "### Finishing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets import settings of the network\n",
    "#     the optimizer is RMSprop, another option would be Stochastic Gradient Descent\n",
    "#     the network computes the accuracy and the mae=mean absolute error after each epoch\n",
    "#     the network tries to optimize the categorical_crossentropy\n",
    "model.compile(optimizer='RMSprop',\n",
    "              metrics=['accuracy', 'mae'],\n",
    "              loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# History will be dictionary with the data about the training process\n",
    "# model.fit launches the training loop\n",
    "# batch_size defines how many samples to process at once\n",
    "# epochs=16 means thath the model will process every sample 16 times\n",
    "history = model.fit(x=train_data,\n",
    "                    y=train_labels,\n",
    "                    batch_size=128, \n",
    "                    epochs=16,\n",
    "                    validation_data=(val_data, val_labels), \n",
    "                    shuffle=True,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To train it's either model.fit or model.fit_generator. If the data is in form of a generator, choose the later\n",
    "#    worker=8 means to run on 8 threads\n",
    "#    max_queue_size limit the length of the queue to wait for training\n",
    "history = model.fit_generator(generator=training_generator,\n",
    "                              epochs=10,\n",
    "                              validation_data=(val_data, val_labels), \n",
    "                              shuffle=True,\n",
    "                              use_multiprocessing=True,\n",
    "                              workers=8,\n",
    "                              max_queue_size=20,          \n",
    "                              callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a keras Model from a .h5 file\n",
    "#     custom_objects=[...] is required for it to recognize the kapre layers\n",
    "loaded_model = keras.models.load_model('berlin_net/berlin_net.h5', custom_objects={'Melspectrogram':Melspectrogram, \n",
    "                                                                             'Normalization2D': Normalization2D})\n",
    "# Evaluate a Model on test_data\n",
    "#     model.evaluate return array with accuracy and loss\n",
    "#     model.metrics_names return array with names of used metrics\n",
    "loaded_model.evaluate(x=test_data,\n",
    "                      y=test_labels), loaded_model.metrics_names"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
