{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Convnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import models, layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from kapre.time_frequency import Melspectrogram\n",
    "from kapre.utils import Normalization2D\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils import DataFeed\n",
    "from keras import regularizers\n",
    "from keras.optimizers import RMSprop, Nadam\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path='../preprocessing/preprocessed_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data, train_labels = DataFeed.Dataset.create(data_path, ['train/voxforge', 'train/youtube'], num=50000, use_premade=True)\n",
    "val_data, val_labels = DataFeed.Dataset.create(data_path, ['val/youtube', 'val/voxforge'], num=-1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "callback_stopearly = keras.callbacks.EarlyStopping(monitor='val_acc',\n",
    "                                                   patience=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topcoder_net\n",
    "based on [repo](https://github.com/pietz/language-recognition/blob/master/Language%20Classifier.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(Melspectrogram(n_dft=512, input_shape=(1, 5 * 16000,),\n",
    "                         padding='same', sr=16000, n_mels=192, n_hop=418,\n",
    "                         fmin=0.0, fmax=8000, power_melgram=1.0,\n",
    "                         return_decibel_melgram=False, trainable_fb=False,\n",
    "                         trainable_kernel=False))\n",
    "model.add(layers.Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "model.add(layers.SeparableConv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "model.add(layers.Dense(3, activation='softmax'))\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> up to xxx%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications import vgg16, resnet50\n",
    "from keras_contrib.applications.resnet import ResNet18, ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "                            featurewise_center=True,\n",
    "                            featurewise_std_normalization=True,\n",
    "                            rotation_range=20,\n",
    "                            width_shift_range=0.2,\n",
    "                            height_shift_range=0.2,\n",
    "                            horizontal_flip=True,\n",
    "                            dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshaping via a convolution...\n",
      "reshaping via a convolution...\n",
      "reshaping via a convolution...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "melspectrogram_18 (Melspectr (None, 192, 192, 1)       312512    \n",
      "_________________________________________________________________\n",
      "model_8 (Model)              (None, 3)                 2788419   \n",
      "=================================================================\n",
      "Total params: 3,100,931\n",
      "Trainable params: 2,783,811\n",
      "Non-trainable params: 317,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(Melspectrogram(n_dft=512, input_shape=(1, 5 * 16000,),\n",
    "                         padding='same', sr=16000, n_mels=192, n_hop=418,\n",
    "                         fmin=0.0, fmax=8000, power_melgram=1.0,\n",
    "                         return_decibel_melgram=False, trainable_fb=False,\n",
    "                         trainable_kernel=False))\n",
    "#model.add(layers.Lambda(baum)) try using data augmentation\n",
    "model.add(ResNet(input_shape=(192, 192, 1), classes=3, block='basic', repetitions=[2, 2, 2], dropout=0.5))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> up to 76% val_acc, overfits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=RMSprop(lr=0.001, decay=1e-8),\n",
    "              metrics=['accuracy'],\n",
    "              loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "49792/50000 [============================>.] - ETA: 0s - loss: 0.7944 - acc: 0.6447"
     ]
    }
   ],
   "source": [
    "model.fit(train_data, train_labels, \n",
    "          epochs=2,\n",
    "          batch_size=64,\n",
    "          shuffle=True,\n",
    "          validation_data=(val_data, val_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepLID",
   "language": "python",
   "name": "deeplid"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
