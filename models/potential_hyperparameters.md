## Base Architecture

- Number of Layers

- Type of Layers
  - Dense → good for last layer

  - Convolutional

  - Recurrent

- Size of Layers

## Extended Architecture

- Optimisers
  - [ ] Rmsprop → always a good choice
- Loss functions
  - [ ] Cross  Entropy
- Activations
  - Relu → most common
  - Softmax → returns probability distribution
- Metrics
  - Accuracy
  - ROC AUC
- Dropout
- Batch Size
- Regularization
  - L2
  - L1

## Preprocessing

- Normalization
  -  Normalize every sample independently?
- Mel-Spectrograms or Raw

## Other

- Batch Normalization

- Adaptive Learning rate
- Transfer Learning