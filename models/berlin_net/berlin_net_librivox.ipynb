{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Berlin Net trained on the Librivox Dataset\n",
    "Does this lead to better robustness towards the guru dataset?\n",
    "\n",
    "**Conclusion:** No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet_ml import Experiment\n",
    "import keras\n",
    "from keras import models, layers\n",
    "from keras.optimizers import RMSprop\n",
    "import numpy as np\n",
    "from kapre.time_frequency import Melspectrogram\n",
    "from kapre.augmentation import AdditiveNoise\n",
    "from kapre.utils import Normalization2D\n",
    "from keras import regularizers\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../')\n",
    "from utils import DataFeed\n",
    "\n",
    "# to avoid different initizialization of weights\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdditionalValidationSets(keras.callbacks.Callback):\n",
    "    def __init__(self, validation_sets, verbose=0, batch_size=None):\n",
    "        \"\"\"\n",
    "        :param validation_sets:\n",
    "        a list of 3-tuples (validation_data, validation_targets, validation_set_name)\n",
    "        or 4-tuples (validation_data, validation_targets, sample_weights, validation_set_name)\n",
    "        :param verbose:\n",
    "        verbosity mode, 1 or 0\n",
    "        :param batch_size:\n",
    "        batch size to be used when evaluating on the additional datasets\n",
    "        \"\"\"\n",
    "        super(AdditionalValidationSets, self).__init__()\n",
    "        self.validation_sets = validation_sets\n",
    "        for validation_set in self.validation_sets:\n",
    "            if len(validation_set) not in [2, 3]:\n",
    "                raise ValueError()\n",
    "        self.epoch = []\n",
    "        self.history = {}\n",
    "        self.verbose = verbose\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.epoch = []\n",
    "        self.history = {}\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        self.epoch.append(epoch)\n",
    "\n",
    "        # record the same values as History() as well\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "\n",
    "        # evaluate on the additional validation sets\n",
    "        for validation_set in self.validation_sets:\n",
    "            if len(validation_set) == 3:\n",
    "                validation_data, validation_targets, validation_set_name = validation_set\n",
    "                sample_weights = None\n",
    "            elif len(validation_set) == 4:\n",
    "                validation_data, validation_targets, sample_weights, validation_set_name = validation_set\n",
    "            else:\n",
    "                raise ValueError()\n",
    "    \n",
    "            results = self.model.evaluate(x=validation_data,\n",
    "                                          y=validation_targets,\n",
    "                                          verbose=self.verbose,\n",
    "                                          batch_size=self.batch_size)\n",
    "\n",
    "            print(f\"{validation_set_name}: {model.metrics_names[0]} = {results[0]},  {model.metrics_names[1]} = {results[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../preprocessing/preprocessed_data'\n",
    "\n",
    "training_generator = DataFeed.DataGenerator(data_path, ['train/librivox'], batch_size=32)\n",
    "val_data, val_labels = DataFeed.Dataset.create(data_path, ['test/guru'], num=-1, shuffle=True)\n",
    "val_data2, val_labels2 = DataFeed.Dataset.create(data_path, ['val/voxforge'], num=-1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [keras.callbacks.EarlyStopping(monitor='val_acc', patience=5),\n",
    "             keras.callbacks.ModelCheckpoint('berlin_net_librivox.h5', monitor='val_loss', save_best_only=True),\n",
    "             AdditionalValidationSets([(val_data2, val_labels2, 'voxforge')], verbose=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(Melspectrogram(n_dft=512, input_shape=(1, 5 * 16000,),\n",
    "                         padding='same', sr=16000, n_mels=28,\n",
    "                         fmin=50, fmax=8000, power_melgram=1.0,\n",
    "                         return_decibel_melgram=True, trainable_fb=False,\n",
    "                         trainable_kernel=False))\n",
    "model.add(Normalization2D(str_axis='freq'))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(1048, activation='relu'))\n",
    "model.add(layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=RMSprop(),\n",
    "              metrics=['accuracy'],\n",
    "              loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "4567/4567 [==============================] - 213s 47ms/step - loss: 0.5194 - acc: 0.7917 - val_loss: 0.7195 - val_acc: 0.6667\n",
      "voxforge: loss = 0.8354952196121216,  acc = 0.6268\n",
      "Epoch 2/8\n",
      "4567/4567 [==============================] - 211s 46ms/step - loss: 0.3520 - acc: 0.8827 - val_loss: 0.7343 - val_acc: 0.7536\n",
      "voxforge: loss = 0.8962148693084717,  acc = 0.6172\n",
      "Epoch 3/8\n",
      "4567/4567 [==============================] - 213s 47ms/step - loss: 0.3562 - acc: 0.8841 - val_loss: 0.6813 - val_acc: 0.7391\n",
      "voxforge: loss = 0.7341104091644287,  acc = 0.6844\n",
      "Epoch 4/8\n",
      "4567/4567 [==============================] - 209s 46ms/step - loss: 0.3710 - acc: 0.8812 - val_loss: 0.8314 - val_acc: 0.7246\n",
      "voxforge: loss = 0.7872097562789917,  acc = 0.656\n",
      "Epoch 5/8\n",
      "4567/4567 [==============================] - 209s 46ms/step - loss: 0.3969 - acc: 0.8746 - val_loss: 1.3334 - val_acc: 0.6522\n",
      "voxforge: loss = 0.7914732672691345,  acc = 0.68\n",
      "Epoch 6/8\n",
      " 751/4567 [===>..........................] - ETA: 2:44 - loss: 0.4109 - acc: 0.8723"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(training_generator,\n",
    "                              epochs=8,\n",
    "                              validation_data=(val_data[:-1], val_labels[:-1]), \n",
    "                              shuffle=True,\n",
    "                              callbacks=callbacks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
