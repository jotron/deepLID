{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Berlin Net\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from comet_ml import Experiment\n",
    "import keras\n",
    "from keras import models, layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from kapre.time_frequency import Melspectrogram\n",
    "from kapre.utils import Normalization2D\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils import DataFeed\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Similar Architecture to [paper](https://github.com/twerkmeister/iLID/blob/master/Deep%20Audio%20Paper%20Thomas%20Werkmeister%2C%20Tom%20Herold.pdf)\n",
    "\n",
    "Changes:\n",
    "- add dropout\n",
    "- no pooling stride\n",
    "- remove batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "melspectrogram_1 (Melspectro (None, 28, 313, 1)        270364    \n",
      "_________________________________________________________________\n",
      "normalization2d_1 (Normaliza (None, 28, 313, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 26, 311, 64)       640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 155, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 153, 64)       36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 76, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 74, 128)        73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 37, 128)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 37, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4736)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              4850688   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 3075      \n",
      "=================================================================\n",
      "Total params: 5,235,551\n",
      "Trainable params: 4,965,187\n",
      "Non-trainable params: 270,364\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(Melspectrogram(n_dft=512, input_shape=(1, 5 * 16000,),\n",
    "                         padding='same', sr=16000, n_mels=28,\n",
    "                         fmin=0.0, fmax=10000, power_melgram=1.0,\n",
    "                         return_decibel_melgram=True, trainable_fb=False,\n",
    "                         trainable_kernel=False))\n",
    "model.add(Normalization2D(str_axis='data_sample'))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(1024, activation='relu'))\n",
    "model.add(layers.Dense(3, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='RMSprop',\n",
    "              metrics=['accuracy', 'mae'],\n",
    "              loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on 50'000 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../preprocessing/preprocessed_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels = DataFeed.Dataset.create(data_path, ['train/voxforge', 'train/youtube'], num=50000, use_premade=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data, val_labels = DataFeed.Dataset.create(data_path, ['val/youtube', 'val/voxforge'], num=-1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [keras.callbacks.EarlyStopping(monitor='val_acc', patience=5),\n",
    "             keras.callbacks.ModelCheckpoint('berlin_net_small.h5', monitor='val_loss', save_best_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/16\n",
      "50000/50000 [==============================] - 44s 886us/step - loss: 0.9326 - acc: 0.5491 - mean_absolute_error: 0.3641 - val_loss: 0.8406 - val_acc: 0.5901 - val_mean_absolute_error: 0.3074\n",
      "Epoch 2/16\n",
      "50000/50000 [==============================] - 41s 810us/step - loss: 0.5924 - acc: 0.7528 - mean_absolute_error: 0.2236 - val_loss: 0.4287 - val_acc: 0.8398 - val_mean_absolute_error: 0.1695\n",
      "Epoch 3/16\n",
      "50000/50000 [==============================] - 41s 810us/step - loss: 0.4273 - acc: 0.8314 - mean_absolute_error: 0.1551 - val_loss: 0.3144 - val_acc: 0.8838 - val_mean_absolute_error: 0.1360\n",
      "Epoch 4/16\n",
      "50000/50000 [==============================] - 40s 807us/step - loss: 0.3397 - acc: 0.8687 - mean_absolute_error: 0.1229 - val_loss: 0.4453 - val_acc: 0.8161 - val_mean_absolute_error: 0.1481\n",
      "Epoch 5/16\n",
      "50000/50000 [==============================] - 40s 808us/step - loss: 0.2879 - acc: 0.8892 - mean_absolute_error: 0.1028 - val_loss: 0.3572 - val_acc: 0.8543 - val_mean_absolute_error: 0.1237\n",
      "Epoch 6/16\n",
      "50000/50000 [==============================] - 40s 808us/step - loss: 0.2526 - acc: 0.9050 - mean_absolute_error: 0.0896 - val_loss: 0.4155 - val_acc: 0.8452 - val_mean_absolute_error: 0.1176\n",
      "Epoch 7/16\n",
      "50000/50000 [==============================] - 40s 807us/step - loss: 0.2274 - acc: 0.9160 - mean_absolute_error: 0.0798 - val_loss: 0.2570 - val_acc: 0.9093 - val_mean_absolute_error: 0.0827\n",
      "Epoch 8/16\n",
      "50000/50000 [==============================] - 41s 812us/step - loss: 0.2044 - acc: 0.9248 - mean_absolute_error: 0.0719 - val_loss: 0.3027 - val_acc: 0.8996 - val_mean_absolute_error: 0.0817\n",
      "Epoch 9/16\n",
      "50000/50000 [==============================] - 41s 829us/step - loss: 0.1884 - acc: 0.9312 - mean_absolute_error: 0.0652 - val_loss: 0.2687 - val_acc: 0.9081 - val_mean_absolute_error: 0.0805\n",
      "Epoch 10/16\n",
      "50000/50000 [==============================] - 42s 835us/step - loss: 0.1752 - acc: 0.9354 - mean_absolute_error: 0.0610 - val_loss: 0.2248 - val_acc: 0.9232 - val_mean_absolute_error: 0.0643\n",
      "Epoch 11/16\n",
      "50000/50000 [==============================] - 42s 831us/step - loss: 0.1675 - acc: 0.9393 - mean_absolute_error: 0.0574 - val_loss: 0.3184 - val_acc: 0.8967 - val_mean_absolute_error: 0.0895\n",
      "Epoch 12/16\n",
      "50000/50000 [==============================] - 41s 827us/step - loss: 0.1630 - acc: 0.9427 - mean_absolute_error: 0.0553 - val_loss: 0.3348 - val_acc: 0.8954 - val_mean_absolute_error: 0.0882\n",
      "Epoch 13/16\n",
      "50000/50000 [==============================] - 41s 822us/step - loss: 0.1567 - acc: 0.9447 - mean_absolute_error: 0.0527 - val_loss: 0.2720 - val_acc: 0.9260 - val_mean_absolute_error: 0.0556\n",
      "Epoch 14/16\n",
      "50000/50000 [==============================] - 41s 815us/step - loss: 0.1515 - acc: 0.9466 - mean_absolute_error: 0.0504 - val_loss: 0.5889 - val_acc: 0.8326 - val_mean_absolute_error: 0.1219\n",
      "Epoch 15/16\n",
      "50000/50000 [==============================] - 41s 817us/step - loss: 0.1435 - acc: 0.9489 - mean_absolute_error: 0.0482 - val_loss: 0.2047 - val_acc: 0.9385 - val_mean_absolute_error: 0.0519\n",
      "Epoch 16/16\n",
      "50000/50000 [==============================] - 41s 816us/step - loss: 0.1406 - acc: 0.9511 - mean_absolute_error: 0.0465 - val_loss: 0.1855 - val_acc: 0.9346 - val_mean_absolute_error: 0.0576\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=train_data,\n",
    "                    y=train_labels,\n",
    "                    batch_size=128, \n",
    "                    epochs=16,\n",
    "                    validation_data=(val_data, val_labels), \n",
    "                    shuffle=True,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 41s 812us/step - loss: 0.1393 - acc: 0.9522 - mean_absolute_error: 0.0453 - val_loss: 0.3222 - val_acc: 0.9086 - val_mean_absolute_error: 0.0709\n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 41s 816us/step - loss: 0.1340 - acc: 0.9545 - mean_absolute_error: 0.0430 - val_loss: 0.4171 - val_acc: 0.8355 - val_mean_absolute_error: 0.1259\n",
      "Epoch 3/5\n",
      "11008/50000 [=====>........................] - ETA: 27s - loss: 0.1268 - acc: 0.9555 - mean_absolute_error: 0.0424"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-216cc62cd3f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                     \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                     callbacks=callbacks)\n\u001b[0m",
      "\u001b[0;32m~/.local/share/virtualenvs/deepLID-B2i2hIZa/lib/python3.6/site-packages/comet_ml/monkey_patching.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    241\u001b[0m                     )\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0mreturn_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;31m# Call after callbacks once we have the return value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/deepLID-B2i2hIZa/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.local/share/virtualenvs/deepLID-B2i2hIZa/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/deepLID-B2i2hIZa/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/deepLID-B2i2hIZa/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2653\u001b[0m                 array_vals.append(\n\u001b[1;32m   2654\u001b[0m                     np.asarray(value,\n\u001b[0;32m-> 2655\u001b[0;31m                                dtype=tf.as_dtype(tensor.dtype).as_numpy_dtype))\n\u001b[0m\u001b[1;32m   2656\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2657\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/deepLID-B2i2hIZa/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m     \"\"\"\n\u001b[0;32m--> 492\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(x=train_data,\n",
    "                    y=train_labels,\n",
    "                    batch_size=128, \n",
    "                    epochs=5,\n",
    "                    validation_data=(val_data, val_labels), \n",
    "                    shuffle=True,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int_axis=0 passed but is ignored, str_axis is used instead.\n",
      "10000/10000 [==============================] - 6s 568us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.18541387659870087, 0.9369, 0.05716399599462747],\n",
       " ['loss', 'acc', 'mean_absolute_error'])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_model = keras.models.load_model('berlin_net_small.h5', custom_objects={'Melspectrogram':Melspectrogram, \n",
    "                                                                             'Normalization2D': Normalization2D})\n",
    "tet_data, test_labels = DataFeed.Dataset.create(data_path, ['test/youtube', 'test/voxforge'], num=-1, shuffle=True)\n",
    "small_model.evaluate(x=test_data,\n",
    "                     y=test_labels), model.metrics_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model on 100'000 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator = DataFeed.DataGenerator(data_path, ['train/voxforge', 'train/youtube'], num=-1, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [keras.callbacks.EarlyStopping(monitor='val_acc', patience=3),\n",
    "             keras.callbacks.ModelCheckpoint('berlin_net.h5', monitor='val_loss', save_best_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 113s 181ms/step - loss: 0.8290 - acc: 0.6133 - mean_absolute_error: 0.3218 - val_loss: 0.5446 - val_acc: 0.7686 - val_mean_absolute_error: 0.2212\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 107s 171ms/step - loss: 0.4618 - acc: 0.8158 - mean_absolute_error: 0.1703 - val_loss: 0.3889 - val_acc: 0.8408 - val_mean_absolute_error: 0.1507\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 103s 165ms/step - loss: 0.3340 - acc: 0.8724 - mean_absolute_error: 0.1192 - val_loss: 0.4751 - val_acc: 0.7852 - val_mean_absolute_error: 0.1743\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 106s 170ms/step - loss: 0.2779 - acc: 0.8951 - mean_absolute_error: 0.0981 - val_loss: 0.2521 - val_acc: 0.9102 - val_mean_absolute_error: 0.0930\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 104s 167ms/step - loss: 0.2414 - acc: 0.9103 - mean_absolute_error: 0.0849 - val_loss: 0.4489 - val_acc: 0.8409 - val_mean_absolute_error: 0.1257\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 103s 165ms/step - loss: 0.2224 - acc: 0.9176 - mean_absolute_error: 0.0774 - val_loss: 0.1887 - val_acc: 0.9298 - val_mean_absolute_error: 0.0625\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 108s 173ms/step - loss: 0.2034 - acc: 0.9260 - mean_absolute_error: 0.0702 - val_loss: 0.1586 - val_acc: 0.9433 - val_mean_absolute_error: 0.0535\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 106s 170ms/step - loss: 0.1936 - acc: 0.9304 - mean_absolute_error: 0.0659 - val_loss: 0.1766 - val_acc: 0.9342 - val_mean_absolute_error: 0.0571\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 106s 170ms/step - loss: 0.1797 - acc: 0.9349 - mean_absolute_error: 0.0616 - val_loss: 0.1518 - val_acc: 0.9442 - val_mean_absolute_error: 0.0502\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 108s 172ms/step - loss: 0.1763 - acc: 0.9372 - mean_absolute_error: 0.0598 - val_loss: 0.1549 - val_acc: 0.9443 - val_mean_absolute_error: 0.0610\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(generator=training_generator,\n",
    "                              epochs=10,\n",
    "                              validation_data=(val_data, val_labels), \n",
    "                              shuffle=True,\n",
    "                              use_multiprocessing=True,\n",
    "                              workers=8,\n",
    "                              max_queue_size=20,          \n",
    "                              callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1653 - acc: 0.9410 - mean_absolute_error: 0.0558Epoch 1/5\n",
      "625/625 [==============================] - 105s 168ms/step - loss: 0.1652 - acc: 0.9411 - mean_absolute_error: 0.0558 - val_loss: 0.1496 - val_acc: 0.9478 - val_mean_absolute_error: 0.0489\n",
      "Epoch 2/5\n",
      "625/625 [==============================] - 108s 172ms/step - loss: 0.1644 - acc: 0.9411 - mean_absolute_error: 0.0552 - val_loss: 0.1484 - val_acc: 0.9487 - val_mean_absolute_error: 0.0492\n",
      "Epoch 3/5\n",
      "625/625 [==============================] - 104s 166ms/step - loss: 0.1600 - acc: 0.9442 - mean_absolute_error: 0.0530 - val_loss: 0.1548 - val_acc: 0.9429 - val_mean_absolute_error: 0.0606\n",
      "Epoch 4/5\n",
      "625/625 [==============================] - 107s 171ms/step - loss: 0.1552 - acc: 0.9455 - mean_absolute_error: 0.0518 - val_loss: 0.1513 - val_acc: 0.9458 - val_mean_absolute_error: 0.0539\n",
      "Epoch 5/5\n",
      "625/625 [==============================] - 105s 168ms/step - loss: 0.1536 - acc: 0.9464 - mean_absolute_error: 0.0502 - val_loss: 0.1763 - val_acc: 0.9410 - val_mean_absolute_error: 0.0514\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(generator=training_generator,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_data, val_labels), \n",
    "                              shuffle=True,\n",
    "                              use_multiprocessing=True,\n",
    "                              workers=8,\n",
    "                              max_queue_size=20,          \n",
    "                              callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int_axis=0 passed but is ignored, str_axis is used instead.\n",
      "10000/10000 [==============================] - 5s 547us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.141640976549685, 0.9511, 0.04648835944905877],\n",
       " ['loss', 'acc', 'mean_absolute_error'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_model = keras.models.load_model('berlin_net/berlin_net.h5', custom_objects={'Melspectrogram':Melspectrogram, \n",
    "                                                                             'Normalization2D': Normalization2D})\n",
    "#test_data, test_labels = DataFeed.Dataset.create(data_path, ['test/youtube', 'test/voxforge'], num=-1, shuffle=True)\n",
    "big_model.evaluate(x=test_data,\n",
    "                   y=test_labels), big_model.metrics_names"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
